{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Analysis of time series data with PolyTrend trend-detection algorithm</h1>\n",
    "<p>This script allows you to use Google Earth Engine API to import and analyze time series data. You can analyze a total of 1 000 000 pixels at once. If you experience problems authenticating GEE, try: <a href=\"https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/authorize_notebook_server.ipynb\">https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/authorize_notebook_server.ipynb</a></p>\n",
    "<h3>Step 1. Import libraries below.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries for PolyTrend algorithm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.linalg as lng\n",
    "import numpy.polynomial.polynomial as poly\n",
    "import scipy.stats as stats\n",
    "from ipyleaflet import Map, basemaps, DrawControl, basemap_to_tiles, CircleMarker\n",
    "try:\n",
    "    import ee\n",
    "except ImportError:\n",
    "    raise ImportError(\"You either haven't installed or authenticated Earth Engine\")\n",
    "    \n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 2. Enter parameters:</h3>\n",
    "<br>\n",
    "<ul>\n",
    "    <li>Statistical significance (alpha), the default value is 0.05.</li> \n",
    "    <li>Coordinates of the region of interest. If you don't know them use the map, mark a polygon. Only the coordinates of the last polygon drawn will be used.</li>\n",
    "    <li>ID of the dataset you'd like to use. Check its ID <a href=\"https://developers.google.com/earth-engine/datasets/catalog/\">here</a>. Enter as variable name_of_collection.</li>\n",
    "    <li>Start and end dates as strings to determine date range.</li>\n",
    "    <li>Name of the band you want to analyse. This is case sensitive so please check what band names the dataset has on Earth Engine website.</li>\n",
    "    <li>Threshold for minimum of analyzed values, eg. for NDVI it could be 0.2 to exclude water bodies. Please check what range is offered by the sensor you are using.</li>\n",
    "    <li>Nominal scale in meters of the projection to work in.</li>\n",
    "</ul>\n",
    "\n",
    "<h4>Make sure to use the same type of data as in the example below, string for collection name, dates and band name, alpha, ndvi_threshold and scale should be numerical. If you are using your own coordinates enter them as [longitude, latitude], uncomment the line.</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style='color:red'>Change the right side of the equation keeping the same format and type of data as in the example</h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "name_of_collection = 'NASA/GIMMS/3GV0'\n",
    "start_year = 2000\n",
    "end_year = 2010\n",
    "scale = 8000\n",
    "band_name = 'ndvi'\n",
    "ndvi_threshold = 0.1 #values from 0.1 up will be considered\n",
    "collection = ee.ImageCollection(name_of_collection)\n",
    "#optionally, example coordinates (comment out if not needed):\n",
    "coords = [[48.79,28.28], [48.79,37.27], [49.16,37.27], [49.16,28.28], [48.79,28.28]]\n",
    "print('Ready to go to the next step.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = Map(\n",
    "    center=(52.7074899764885, 23.68025368663166),\n",
    "    zoom=10\n",
    ")\n",
    "#enable drawing tools\n",
    "draw_control = DrawControl()\n",
    "draw_control.polygon = {\n",
    "    \"shapeOptions\": {\n",
    "        \"fillColor\": \"#6be5c3\",\n",
    "        \"color\": \"#6be5c3\",\n",
    "        \"fillOpacity\": 1.0\n",
    "    },\n",
    "    \"drawError\": {\n",
    "        \"color\": \"#dd253b\",\n",
    "        \"message\": \"Oups!\"\n",
    "    },\n",
    "    \"allowIntersection\": False\n",
    "}\n",
    "\n",
    "m.add_control(draw_control)\n",
    "m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if coordinates are ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = draw_control.last_draw['geometry']['coordinates']\n",
    "print(coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 4. Generate annual mean NDVI composite.</h3><br>\n",
    "<i>Please note: \n",
    "    <ul>\n",
    "    <li>Only the last polygon marked will be used. If you are using a point, you have to change the geometry inside the script so that AOI = ee.Geometry.Point(coords)</li>\n",
    "    <li>To generate maximum annual value instead of mean change the word 'mean' to 'max' in \n",
    "        line 12 </li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list of years\n",
    "years = ee.List.sequence(start_year, end_year, 1)\n",
    "\n",
    "def calculateAnnualMean(year_and_collection):\n",
    "  # Unpack variable from the input parameter\n",
    "    year_and_collection = ee.List(year_and_collection)\n",
    "    year = ee.Number(year_and_collection.get(0))\n",
    "    _collection = ee.ImageCollection(year_and_collection.get(1))\n",
    "    start_date = ee.Date.fromYMD(year, 1, 1)\n",
    "    end_date = start_date.advance(1, 'year')\n",
    "   \n",
    "    return  _collection.filterDate(start_date, end_date).mean().set('system:time_start', year)\n",
    "\n",
    "# Create a list of year-collection pairs (i.e. pack the function inputs)\n",
    "list_of_years_and_collections = years.zip(ee.List.repeat(collection, years.length()))\n",
    "\n",
    "annualNdvi = ee.ImageCollection.fromImages(list_of_years_and_collections.map(calculateAnnualMean))\n",
    "print(annualNdvi.size().getInfo())\n",
    "def GetDataFrame(coords):\n",
    "    #for point feature change the line below\n",
    "    AOI = ee.Geometry.Polygon(coords)\n",
    "    crs = annualNdvi.first().getInfo()['bands'][0]['crs']\n",
    "    geom_values = annualNdvi.getRegion(geometry=AOI, scale=scale, crs=crs)\n",
    "    geom_values_list = ee.List(geom_values).getInfo()\n",
    "    # Convert to a Pandas DataFrame.\n",
    "    header = geom_values_list[0]\n",
    "    data = pd.DataFrame(geom_values_list[1:], columns=header)\n",
    "    data['datetime'] = pd.to_datetime(data['time'], unit='ms', utc=True)\n",
    "    data.set_index('time')\n",
    "    data.groupby(['longitude', 'latitude'])\n",
    "    return data;\n",
    "\n",
    "dataset = GetDataFrame(coords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Step 4a. Alternatively, save the time series for the polygon. It saves to the active Anaconda environment as time_series.csv.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('time_series.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 5. Run PolyTrend algorithm per pixel. It will take a while to complete, dependent on the size of your data set.</h3>\n",
    "<p><i>Watch for a message saying 'Running this process ended successfully.' below the cell</i><p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = 'Please wait for a message that the process is completed...'\n",
    "#definition of the PolyTrend algorithm\n",
    "def PolyTrend(Y, alpha):\n",
    "    X = range(1, len(Y)+1)\n",
    " \n",
    "    #define function to find p value:\n",
    "    def Pvalue(coef, df, A, Aprim, pn):\n",
    "        #generate square residual\n",
    "        part_res = np.dot(A, pn)-Y\n",
    "        residual = np.dot(part_res.transpose(), part_res)\n",
    "        #generate variance-covariance matrix\n",
    "        VC = lng.inv(np.dot(Aprim, A))*residual/df\n",
    "        #compute variance of the first coefficient\n",
    "        VC1 = np.sqrt(VC[0,0])\n",
    "        #compute t-statistic\n",
    "        statistic = coef/VC1\n",
    "        #compute p value\n",
    "        p = 2*(1 - stats.t.cdf(np.abs(statistic),df=df))\n",
    "        return p;\n",
    "    \n",
    "    def Plinear(X, Y):\n",
    "        df1 = len(X)-2\n",
    "        #generate Vandermonde matrix\n",
    "        A1 = np.vander(X, 2)\n",
    "        #generate transpose of the Vandermonde matrix\n",
    "        Aprim1 = A1.transpose()\n",
    "        p1 = np.dot(np.dot((lng.inv(np.dot(Aprim1, A1))), Aprim1), Y)\n",
    "        coef1 = p1[0]\n",
    "        Plin = Pvalue(coef1, df1, A1, Aprim1, p1)\n",
    "        Slope = p1[0]\n",
    "        Direction = np.sign(Slope)\n",
    "        #Slope and Direction will be referred to Plin[1] and Plin[2] respectively in returned results\n",
    "        return Plin, Slope, Direction;\n",
    "    \n",
    "    #degrees of freedom\n",
    "    df3 = len(X)-4\n",
    "    #generate Vandermonde matrix\n",
    "    A3 = np.vander(X, 4)\n",
    "    #generate transpose of the Vandermonde matrix\n",
    "    Aprim3 = A3.transpose()\n",
    "    #X=inv(A'*A)*A'*L - creating coefficients matrix:\n",
    "    p3 = np.dot(np.dot((lng.inv(np.dot(Aprim3, A3))), Aprim3), Y)\n",
    "    coef3 = p3[0]\n",
    "    #compute p-value for cubic fit\n",
    "    Pcubic = Pvalue(coef3, df3, A3, Aprim3, p3)\n",
    "    #get roots of cubic polynomial\n",
    "    coefs3 = ([p3[2], 2*p3[1], 3*p3[0]])\n",
    "    roots3 = np.sort(poly.polyroots(coefs3))\n",
    "\n",
    "    if (np.imag(roots3[0]) == 0 and np.imag(roots3[1])==0 and roots3[0] != roots3[1] and X[0] <= roots3[0] <= X[-1] and X[0] <= roots3[1] <= X[-1] and Pcubic < alpha):\n",
    "        Plin = Plinear(X, Y)\n",
    "        if (Plin[0] < alpha):\n",
    "            Trend_type = 3\n",
    "            Significance = 1\n",
    "            Poly_degree = 3\n",
    "        else:\n",
    "            Trend_type = -1\n",
    "            Significance = -1\n",
    "            Poly_degree = 3\n",
    "            return [Trend_type, Significance, Poly_degree, Plin[1], Plin[2], Y];\n",
    "    else:\n",
    "        df2 = len(X)-3\n",
    "        A2 = np.vander(X, 3)\n",
    "        Aprim2 = A2.transpose()\n",
    "        p2 = np.dot(np.dot((lng.inv(np.dot(Aprim2, A2))), Aprim2), Y)\n",
    "        coef2 = p2[0]\n",
    "        Pquadratic = Pvalue(coef2, df2, A2, Aprim2, p2)\n",
    "        coefs2 = ([p2[1], 2*p2[0]])\n",
    "        roots2 = np.sort(poly.polyroots(coefs2))\n",
    "        \n",
    "        if (X[0] <= roots2 <= X[-1] and Pquadratic < alpha):\n",
    "            Plin = Plinear(X, Y)\n",
    "            if Plin[0] < alpha:\n",
    "                Trend_type = 2\n",
    "                Significance = 1\n",
    "                Poly_degree = 2\n",
    "            else:\n",
    "                Trend_type = -1\n",
    "                Significance = -1\n",
    "                Poly_degree = 2\n",
    "                return [Trend_type, Significance, Poly_degree, Plin[1], Plin[2], Y];\n",
    "                \n",
    "        else:\n",
    "            Plin = Plinear(X, Y)\n",
    "            if Plin[0] < alpha:\n",
    "                Trend_type = 1\n",
    "                Significance = 1\n",
    "                Poly_degree = 1\n",
    "            else:\n",
    "                Trend_type = 0\n",
    "                Significance = -1\n",
    "                Poly_degree = 0\n",
    "            return [Trend_type, Significance, Poly_degree, Plin[1], Plin[2], Y];     \n",
    "        return [Trend_type, Significance, Poly_degree, Plin[1], Plin[2], Y];\n",
    "    return [Trend_type, Significance, Poly_degree, Plin[1], Plin[2], Y];\n",
    "#end of PolyTrend definition\n",
    "\n",
    "#establish how many images there are in the collection\n",
    "list_of_images = dataset['id']\n",
    "ids_of_images = []\n",
    "for img_id in list_of_images:\n",
    "    if img_id not in ids_of_images:\n",
    "        ids_of_images.append(img_id)\n",
    "        \n",
    "n = len(ids_of_images)\n",
    "print('number of images: ', n)\n",
    "number_of_pixels = len(dataset) \n",
    "print('number of pixels analysed: ', number_of_pixels)\n",
    "\n",
    "#make_Y function returns the results of the analysis for each individual pixel identified by its coordinates\n",
    "def make_Y(dataset, alpha):\n",
    "    PT_result = []\n",
    "    #split the dataset into pixel time series\n",
    "    for i in range(0, number_of_pixels, n):\n",
    "        Y = dataset[i:i+n][band_name].values \n",
    "        #eliminate numbers lower than the threshold and any other values that are not numeric\n",
    "        for val in Y:\n",
    "            if val > ndvi_threshold and isinstance(val, (int,float)):\n",
    "                try:\n",
    "                    result = list(PolyTrend(Y, alpha))\n",
    "                except:\n",
    "                    result = ['unqualified', 'unqualified', 'unqualified', 'unqualified', 'unqualified', 'unqualified']\n",
    "            else:\n",
    "                result = ['NA', 'NA', 'NA', 'NA', 'NA', 'NA']\n",
    "        #populate the empty PT_result list with values    \n",
    "        pixel_long = dataset.at[i, 'longitude']\n",
    "        pixel_lat = dataset.at[i, 'latitude']\n",
    "        PT_result_header = ['longitude', 'latitude', 'trend type', 'significance', 'degree', 'slope', 'direction', 'ts']\n",
    "        PT_result.append([pixel_long, pixel_lat, result[0], result[1], result[2], result[3], result[4], result[5]])\n",
    "    #create a data frame for displaying results on a map    \n",
    "    image_frame = pd.DataFrame(PT_result[0:], columns=PT_result_header)\n",
    "    return image_frame;\n",
    "print(message)\n",
    "final_result = make_Y(dataset, alpha)\n",
    "pixels_to_display = len(final_result)\n",
    "\n",
    "#accompanying block of code, needed for the next steps, placed here so that the user can conveniently move to creating maps\n",
    "def assign_color(value):\n",
    "    if value==-1:\n",
    "        return 'gray'\n",
    "    elif value ==0:\n",
    "        return 'yellow'\n",
    "    elif value ==1:\n",
    "        return 'green'\n",
    "    elif value == 2:\n",
    "        return 'blue'\n",
    "    elif value == 3:\n",
    "        return 'red'\n",
    "    elif value == 'unqualified':\n",
    "        return 'violet'\n",
    "    else:\n",
    "        return 'black'\n",
    "\n",
    "print('points produced: ', pixels_to_display)\n",
    "message = 'Process finished successfully. You can save your data to a csv file or display on the maps below.'\n",
    "print(message)\n",
    "\n",
    "center = coords[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 6a. Save results to a csv file in this Anaconda environment.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result.to_csv('final_result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style='color:red'>At the moment if you generate maps with more than 200 pixels, it might crash the program. Instead, you can download a csv file and display it using any desktop GIS that accepts csv files.</h4> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Trend type map</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center = coords[0][1][1], coords[0][1][0]\n",
    "#generate trend type map\n",
    "m_trend = Map(\n",
    "    center=center,\n",
    "    zoom=8\n",
    ")\n",
    "#for i in range(0, 200):\n",
    "for i in range(0, len(final_result)):  \n",
    "    pixel = CircleMarker()\n",
    "    pixel.location = (final_result.at[i, 'latitude'], final_result.at[i, 'longitude'])\n",
    "    pixel.fill_color = assign_color(final_result.at[i, 'trend type'])\n",
    "    pixel.stroke = False\n",
    "    pixel.radius = 5\n",
    "    pixel.fill_opacity = 1.0 \n",
    "    m_trend.add_layer(pixel)\n",
    "    \n",
    "m_trend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Legend:</h3>\n",
    "<ul>\n",
    "    <li><button style='background:gray'>gray</button> - concealed trend</li>\n",
    "    <li><button style='background:yellow'>yellow</button> - no trend</li>\n",
    "    <li><button style='background:green'>green</button> - linear trend</li>\n",
    "    <li><button style='background:blue'>blue</button> - quadratic trend</li>\n",
    "    <li><button style='background:red'>red</button> - cubic trend</li>\n",
    "    <li><button style='background:violet'>violet</button> - unqualified (below threshold)</li>\n",
    "    <li><button style='background:black; color:white'>black</button> - NaN</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Statistical significance map</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center = coords[0][1][1], coords[0][1][0]\n",
    "m_significance = Map(\n",
    "    center=center,\n",
    "    zoom=8\n",
    ")\n",
    "\n",
    "# for i in range(0, 200):\n",
    "for i in range(0, len(final_result)):\n",
    "  \n",
    "    pixel = CircleMarker()\n",
    "    pixel.location = (final_result.at[i, 'latitude'], final_result.at[i, 'longitude'])\n",
    "    pixel.color = assign_color(final_result.at[i, 'significance'])\n",
    "    pixel.fill_color = assign_color(final_result.at[i, 'significance'])\n",
    "    pixel.stroke = False\n",
    "    pixel.radius = 5\n",
    "    pixel.fill_opacity = 1.0 \n",
    "    m_significance.add_layer(pixel)\n",
    "\n",
    "m_significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Legend</h3>\n",
    "<ul>\n",
    "    <li><button style='background:gray'>gray</button> - statistically insignificant</li>\n",
    "    <li><button style='background:green'>green</button> - statistically significant</li>\n",
    "    <li><button style='background:violet'>violet</button> - unqualified (below threshold)</li>\n",
    "    <li><button style='background:black; color:white'>black</button> - NaN</li>\n",
    "            </ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
