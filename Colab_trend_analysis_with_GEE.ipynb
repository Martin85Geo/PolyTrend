{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab_trend_analysis_with_GEE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "7aiV3yRp0G8v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>PolyTrend: Remote sensing time series trend analysis using polynomials</h1>\n",
        "This script enables trend analysis in vegetation time series data with Google Earth Engine Python API. \n",
        "Please make sure you are a registered GEE user. "
      ]
    },
    {
      "metadata": {
        "id": "9kqCShGhjInR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "<h3>Step 1. Install libraries</h3>"
      ]
    },
    {
      "metadata": {
        "id": "H2lJiM_8i_Gw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install earthengine-api"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nsUe3X03jOFw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "<h3>Step 2. Establish connection and authenticate access</h3>"
      ]
    },
    {
      "metadata": {
        "id": "ifHQNPvPjFMq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!earthengine authenticate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qXvP1NgJjm2T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import ee\n",
        "try:\n",
        "  ee.Initialize()\n",
        "  print('The Earth Engine package initialized successfully!')\n",
        "except ee.EEException as e:\n",
        "  print('The Earth Engine package failed to initialize!')\n",
        "except:\n",
        "  print(\"Unexpected error:\", sys.exc_info()[0])\n",
        "  raise"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "apkUSm14Lh8a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h3>Step 3. Import libraries below.</h3>"
      ]
    },
    {
      "metadata": {
        "id": "obip4D8hLh8b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import libraries for PolyTrend algorithm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import numpy.linalg as lng\n",
        "import numpy.polynomial.polynomial as poly\n",
        "import scipy.stats as stats\n",
        "from google.colab import files\n",
        "print(\"Proceed to step 4.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ROY6IY0-Lh8i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h3>Step 4. Enter parameters:</h3>\n",
        "<br>\n",
        "<ul>\n",
        "    <li>Statistical significance (alpha), the default value is 0.05</li> \n",
        "    <li>ID of the dataset you'd like to use. Check its ID <a href=\"https://developers.google.com/earth-engine/datasets/catalog/\">here</a></li>\n",
        "    <li>Start and end dates</li>\n",
        "    <li>Threshold for minimum of analyzed values, eg. for NDVI it could be 0.2 to exclude water bodies. Please check what range is offered by the sensor you are using</li>\n",
        "    <li>Nominal scale in meters per pixel</li>\n",
        "      <li>Coordinates of the region of interest - in the same format as in the example, each coordinate pair in square brackets [long, lat], EPSG: 4326</li>\n",
        "</ul>\n"
      ]
    },
    {
      "metadata": {
        "id": "pKlpALY-Lh8j",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "alpha = 0.05 #@param {type:\"slider\", min:0, max:0.5, step:0.05}\n",
        "name_of_collection = 'NASA/GIMMS/3GV0' #@param ['NASA/GIMMS/3GV0', 'NOAA/CDR/AVHRR/NDVI/V4', 'MODIS/006/MOD13A2'] {allow-input: true}\n",
        "if (name_of_collection == 'NASA/GIMMS/3GV0'):\n",
        "  band_name = 'ndvi'\n",
        "else:\n",
        "  band_name = 'NDVI'\n",
        "start_year = 2000 #@param {type:\"slider\", min:1981, max:2019, step:1}\n",
        "end_year = 2010 #@param {type:\"slider\", min:1981, max:2019, step:1}\n",
        "ndvi_threshold = 0.1 #@param {type:\"slider\", min:-1, max:1, step:0.1}\n",
        "scale = 8000 #@param {type:\"number\"}\n",
        "coords = [[38.79,28.28], [38.79,37.27], [49.16,37.27], [49.16,28.28], [38.79,28.28]] #@param {type: \"raw\"}\n",
        "print('Ready to go to the next step.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yNdWNmArLh8v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h3>Step 4. Generate annual NDVI composites.</h3><br>\n",
        "Choose the type of composite to create."
      ]
    },
    {
      "metadata": {
        "id": "ZRqNHTYmfzQW",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "type_of_composite = 'max' #@param ['mean', 'max'] {allow-input: false}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Li91dVfsisi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Run the next cell to generate a collection of composites."
      ]
    },
    {
      "metadata": {
        "id": "ox8gOB8_Lh8w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if (type_of_composite == 'mean'):\n",
        "  def create_composite(year_and_collection):\n",
        "    # Unpack variable from the input parameter\n",
        "      year_and_collection = ee.List(year_and_collection)\n",
        "      year = ee.Number(year_and_collection.get(0))\n",
        "      _collection = ee.ImageCollection(year_and_collection.get(1))\n",
        "      start_date = ee.Date.fromYMD(year, 1, 1)\n",
        "      end_date = start_date.advance(1, 'year')\n",
        "      return  _collection.filterDate(start_date, end_date).mean().set('system:time_start', year)\n",
        "elif (type_of_composite == 'max'):\n",
        "   def create_composite(year_and_collection):\n",
        "    # Unpack variable from the input parameter\n",
        "      year_and_collection = ee.List(year_and_collection)\n",
        "      year = ee.Number(year_and_collection.get(0))\n",
        "      _collection = ee.ImageCollection(year_and_collection.get(1))\n",
        "      start_date = ee.Date.fromYMD(year, 1, 1)\n",
        "      end_date = start_date.advance(1, 'year')\n",
        "      return  _collection.filterDate(start_date, end_date).max().set('system:time_start', year)\n",
        "AOI = ee.Geometry.Polygon(coords)\n",
        "\n",
        "#The below code is adapted from Tylere on Github: https://gist.github.com/tylere/42e4acf883e18f5b8e331cfab8c91ab5\n",
        "collection = ee.ImageCollection(name_of_collection).select(band_name).filterBounds(AOI)\n",
        "collection = collection.filterDate(ee.Date.fromYMD(start_year, 1, 1), ee.Date.fromYMD(end_year, 1, 1).advance(1, 'year'))\n",
        "#Create list of years\n",
        "years = ee.List.sequence(start_year, end_year, 1)\n",
        "# Create a list of year-collection pairs (i.e. pack the function inputs)\n",
        "list_of_years_and_collections = years.zip(ee.List.repeat(collection, years.length()))\n",
        "\n",
        "annualNdvi = ee.ImageCollection.fromImages(list_of_years_and_collections.map(create_composite))\n",
        "print(annualNdvi.size().getInfo())\n",
        "\n",
        "\n",
        "geom_values = annualNdvi.getRegion(geometry=AOI, scale=scale)\n",
        "geom_values_list = ee.List(geom_values).getInfo()\n",
        "# Convert to a Pandas DataFrame.\n",
        "header = geom_values_list[0]\n",
        "data = pd.DataFrame(geom_values_list[1:], columns=header)\n",
        "data['datetime'] = pd.to_datetime(data['time'], unit='ms', utc=True)\n",
        "data.set_index('time')\n",
        "data.groupby(['longitude', 'latitude'])\n",
        "\n",
        "print(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mn362hSwLh8z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h4>Step 4a. Alternatively, save the time series for the polygon. It saves to the active Google drive folder environment as time_series.csv.</h4>"
      ]
    },
    {
      "metadata": {
        "id": "WF726t6ALh80",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data.to_csv('time_series.csv')\n",
        "files.download('time_series.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nVBm3O_CLh82",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h3>Step 5. Run PolyTrend algorithm per pixel. It will take a while to complete, depending on the size of your data set.</h3>\n",
        "<p><i>Watch for a message saying 'Running this process ended successfully.' below the cell</i><p>"
      ]
    },
    {
      "metadata": {
        "id": "pBuMhgADLh83",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "message = 'Please wait for a message that the process is completed...'\n",
        "#definition of the PolyTrend algorithm\n",
        "def PolyTrend(Y, alpha):\n",
        "    X = range(1, len(Y)+1)\n",
        " \n",
        "    #define function to find p value:\n",
        "    def Pvalue(coef, df, A, Aprim, pn):\n",
        "        #generate square residual\n",
        "        part_res = np.dot(A, pn)-Y\n",
        "        residual = np.dot(part_res.transpose(), part_res)\n",
        "        #generate variance-covariance matrix\n",
        "        VC = lng.inv(np.dot(Aprim, A))*residual/df\n",
        "        #compute variance of the first coefficient\n",
        "        VC1 = np.sqrt(VC[0,0])\n",
        "        #compute t-statistic\n",
        "        statistic = coef/VC1\n",
        "        #compute p value\n",
        "        p = stats.t.sf(np.abs(statistic), df)*2\n",
        "        return p;\n",
        "    \n",
        "    def Plinear(X, Y):\n",
        "        df1 = len(X)-2\n",
        "        #generate Vandermonde matrix\n",
        "        A1 = np.vander(X, 2)\n",
        "        #generate transpose of the Vandermonde matrix\n",
        "        Aprim1 = A1.transpose()\n",
        "        p1 = np.dot(np.dot((lng.inv(np.dot(Aprim1, A1))), Aprim1), Y)\n",
        "        coef1 = p1[0]\n",
        "        Plin = Pvalue(coef1, df1, A1, Aprim1, p1)\n",
        "        Slope = p1[0]\n",
        "        Direction = np.sign(Slope)\n",
        "        #Slope and Direction will be referred to Plin[1] and Plin[2] respectively in returned results\n",
        "        return Plin, Slope, Direction;\n",
        "    \n",
        "    #degrees of freedom\n",
        "    df3 = len(X)-4\n",
        "    #generate Vandermonde matrix\n",
        "    A3 = np.vander(X, 4)\n",
        "    #generate transpose of the Vandermonde matrix\n",
        "    Aprim3 = A3.transpose()\n",
        "    #X=inv(A'*A)*A'*L - creating coefficients matrix:\n",
        "    p3 = np.dot(np.dot((lng.inv(np.dot(Aprim3, A3))), Aprim3), Y)\n",
        "    coef3 = p3[0]\n",
        "    #compute p-value for cubic fit\n",
        "    Pcubic = Pvalue(coef3, df3, A3, Aprim3, p3)\n",
        "    #get roots of cubic polynomial\n",
        "    coefs3 = ([p3[2], 2*p3[1], 3*p3[0]])\n",
        "    roots3 = np.sort(poly.polyroots(coefs3))\n",
        "\n",
        "    if (np.imag(roots3[0]) == 0 and np.imag(roots3[1])==0 and roots3[0] != roots3[1] and X[0] <= roots3[0] <= X[-1] and X[0] <= roots3[1] <= X[-1] and Pcubic < alpha):\n",
        "        Plin = Plinear(X, Y)\n",
        "        if (Plin[0] < alpha):\n",
        "            Trend_type = 3\n",
        "            Significance = 1\n",
        "            Poly_degree = 3\n",
        "        else:\n",
        "            Trend_type = -1\n",
        "            Significance = -1\n",
        "            Poly_degree = 3\n",
        "            return [Trend_type, Significance, Poly_degree, Plin[1], Plin[2]];\n",
        "    else:\n",
        "        df2 = len(X)-3\n",
        "        A2 = np.vander(X, 3)\n",
        "        Aprim2 = A2.transpose()\n",
        "        p2 = np.dot(np.dot((lng.inv(np.dot(Aprim2, A2))), Aprim2), Y)\n",
        "        coef2 = p2[0]\n",
        "        Pquadratic = Pvalue(coef2, df2, A2, Aprim2, p2)\n",
        "        coefs2 = ([p2[1], 2*p2[0]])\n",
        "        roots2 = np.sort(poly.polyroots(coefs2))\n",
        "        \n",
        "        if (X[0] <= roots2 <= X[-1] and Pquadratic < alpha):\n",
        "            Plin = Plinear(X, Y)\n",
        "            if Plin[0] < alpha:\n",
        "                Trend_type = 2\n",
        "                Significance = 1\n",
        "                Poly_degree = 2\n",
        "            else:\n",
        "                Trend_type = -1\n",
        "                Significance = -1\n",
        "                Poly_degree = 2\n",
        "                return [Trend_type, Significance, Poly_degree, Plin[1], Plin[2]];\n",
        "                \n",
        "        else:\n",
        "            Plin = Plinear(X, Y)\n",
        "            if Plin[0] < alpha:\n",
        "                Trend_type = 1\n",
        "                Significance = 1\n",
        "                Poly_degree = 1\n",
        "            else:\n",
        "                Trend_type = 0\n",
        "                Significance = -1\n",
        "                Poly_degree = 0\n",
        "            return [Trend_type, Significance, Poly_degree, Plin[1], Plin[2]];     \n",
        "        return [Trend_type, Significance, Poly_degree, Plin[1], Plin[2]];\n",
        "    return [Trend_type, Significance, Poly_degree, Plin[1], Plin[2]];\n",
        "#end of PolyTrend definition\n",
        "\n",
        "#establish how many images there are in the collection\n",
        "list_of_images = data['id']\n",
        "ids_of_images = []\n",
        "for img_id in list_of_images:\n",
        "    if img_id not in ids_of_images:\n",
        "        ids_of_images.append(img_id)\n",
        "        \n",
        "n = len(ids_of_images)\n",
        "print('number of images: ', n)\n",
        "number_of_pixels = len(data) \n",
        "print('number of pixels analysed: ', number_of_pixels)\n",
        "\n",
        "#make_Y function returns the results of the analysis for each individual pixel identified by its coordinates\n",
        "def make_Y(dataset, alpha):\n",
        "    PT_result = []\n",
        "    #split the dataset into pixel time series\n",
        "    for i in range(0, number_of_pixels, n):\n",
        "        Y = dataset[i:i+n][band_name].values \n",
        "        #eliminate numbers lower than the threshold and any other values that are not numeric\n",
        "        for value in Y:\n",
        "            if value > ndvi_threshold and isinstance(value, (int,float)):\n",
        "                try:\n",
        "                    result = list(PolyTrend(Y, alpha))\n",
        "                except:\n",
        "                    result = ['unqualified', 'unqualified', 'unqualified', 'unqualified', 'unqualified']\n",
        "            else:\n",
        "                result = ['NA', 'NA', 'NA', 'NA', 'NA']\n",
        "        #populate the empty PT_result list with values    \n",
        "        pixel_long = dataset.at[i, 'longitude']\n",
        "        pixel_lat = dataset.at[i, 'latitude']\n",
        "        PT_result_header = ['longitude', 'latitude', 'trend type', 'significance', 'degree', 'slope', 'direction']\n",
        "        PT_result.append([pixel_long, pixel_lat, result[0], result[1], result[2], result[3], result[4]])\n",
        "    #create a data frame for displaying results on a map    \n",
        "    image_frame = pd.DataFrame(PT_result[0:], columns=PT_result_header)\n",
        "    return image_frame;\n",
        "print(message)\n",
        "final_result = make_Y(data, alpha)\n",
        "pixels_to_display = len(final_result)\n",
        "\n",
        "print('points produced: ', pixels_to_display)\n",
        "message = 'Process finished successfully. Save your data to a csv file.'\n",
        "print(message)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XwlGyqN9Lh86",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h3>Step 6. Save results to a csv file in current Google drive folder.</h3>"
      ]
    },
    {
      "metadata": {
        "id": "wzsV3zBkLh87",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "final_result.to_csv('PolyTrend_result.csv')\n",
        "files.download('PolyTrend_result.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}